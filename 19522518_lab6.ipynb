{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC601KJEUAe8"
      },
      "source": [
        "NGUYỄN VĂN QUỐC VIỆT 19522518\n",
        "GIT: https://github.com/vietkitoo/lab6datamining.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL7HaYoMOWzk"
      },
      "source": [
        "1. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N41SlWBOdrL"
      },
      "outputs": [],
      "source": [
        "# import needed libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WIf1U-mO2jI"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab/elonmusk_tweets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvJD0osRPvEi",
        "outputId": "b914a125-b20d-4a18-d1ec-a2f2b5cb4177"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2819, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh3RFwUlPyFq",
        "outputId": "a01544fe-e31f-4b71-88dd-f234d69d5182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2819 entries, 0 to 2818\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          2819 non-null   int64 \n",
            " 1   created_at  2819 non-null   object\n",
            " 2   text        2819 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 66.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6IAevfQMP1zZ",
        "outputId": "60f1dd1f-23e7-4da1-b332-8f547de7837e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fbbc3d73-bd8d-4482-ba64-9faea20a151c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.819000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.804848e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.186404e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.543473e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.506818e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.569719e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.704732e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8.496369e+17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbbc3d73-bd8d-4482-ba64-9faea20a151c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbbc3d73-bd8d-4482-ba64-9faea20a151c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbbc3d73-bd8d-4482-ba64-9faea20a151c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 id\n",
              "count  2.819000e+03\n",
              "mean   5.804848e+17\n",
              "std    2.186404e+17\n",
              "min    1.543473e+10\n",
              "25%    3.506818e+17\n",
              "50%    6.569719e+17\n",
              "75%    7.704732e+17\n",
              "max    8.496369e+17"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpiuHYcdNHyi"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAs4gvRvQRB2",
        "outputId": "e9321f21-a64c-4625-995f-5db87d336e4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['band', 'robot', 'spare', 'human', 'httpstcov7jujqwfcv']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def normalize(document):\n",
        "    # Remove punctuation\n",
        "    text = \"\".join([ch for ch in document if ch not in string.punctuation])\n",
        "    \n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    ret = \" \".join([stemmer.stem(word.lower()) for word in tokens])\n",
        "    \n",
        "    return ret\n",
        "\n",
        "original_documents = [x.strip() for x in df['text']]\n",
        "documents = [normalize(d).split() for d in original_documents]\n",
        "documents[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CUTaXwwbNZY",
        "outputId": "881b8db4-bd3c-479c-b41c-d216225969a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['b',\n",
              " '\"',\n",
              " '@ForIn2020',\n",
              " '@waltmossberg',\n",
              " '@mims',\n",
              " '@defcon_5',\n",
              " 'Exactly',\n",
              " '.',\n",
              " 'Tesla',\n",
              " 'is',\n",
              " 'absurdly',\n",
              " 'overvalued',\n",
              " 'if',\n",
              " 'based',\n",
              " 'on',\n",
              " 'the',\n",
              " 'past',\n",
              " ',',\n",
              " 'but',\n",
              " \"that's\",\n",
              " 'irr',\n",
              " '\\\\',\n",
              " 'xe2',\n",
              " '\\\\',\n",
              " 'x80',\n",
              " '\\\\',\n",
              " 'xa6',\n",
              " 'https://t.co/qQcTqkzgMl',\n",
              " '\"']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        " \n",
        "emoticons_str = r\"\"\"\n",
        "    (?:\n",
        "        [:=;] # Eyes\n",
        "        [oO\\-]? # Nose (optional)\n",
        "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
        "    )\"\"\"\n",
        " \n",
        "regex_str = [\n",
        "    emoticons_str,\n",
        "    r'<[^>]+>', # HTML tags\n",
        "    r'(?:@[\\w_]+)', # @-mentions\n",
        "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
        "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
        " \n",
        "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
        "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
        "    r'(?:[\\w_]+)', # other words\n",
        "    r'(?:\\S)' # anything else\n",
        "]\n",
        "    \n",
        "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
        "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
        " \n",
        "def tokenize(s):\n",
        "    return tokens_re.findall(s)\n",
        " \n",
        "def preprocess(s, lowercase=False):\n",
        "    tokens = tokenize(s)\n",
        "    if lowercase:\n",
        "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
        "    return tokens  \n",
        "original_documents = [x.strip() for x in df['text']]\n",
        "documents = [preprocess(d) for d in original_documents]\n",
        "\n",
        "documents[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7AxE3ZQfUv"
      },
      "source": [
        "2. Implement TF-IDF \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyTRH26PVXUD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL_57a3KVWIh",
        "outputId": "66225d6c-dbc7-4bdc-e918-21eb0a85abe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Tesla', 272)]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['.', \"'\", 'b', '\\\\', '\"']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Flatten all the documents\n",
        "flat_list = [word for doc in documents for word in doc]\n",
        "#TODO: remove stop words from the vocabulary\n",
        "words = [word for word in flat_list if word not in stopwords.words('english')]\n",
        "# TODO: we take the 500 most common words only\n",
        "counts = Counter (words)\n",
        "vocabulary = counts.most_common (500)\n",
        "print([x for x in vocabulary if x[0] == 'Tesla']) \n",
        "vocabulary =  [x[0] for x in vocabulary]\n",
        "assert len (vocabulary) == 500\n",
        "#vocabulary.sort() \n",
        "vocabulary[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOMF6Av9YLmO",
        "outputId": "044e8086-50e4-408a-a131-598c1c694f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.959130577668125,\n",
              " 0.7493007890060756,\n",
              " 1.1177820471225408,\n",
              " 3.1034157579523383,\n",
              " 2.384152165519591]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def idf(vocabulary, documents):\n",
        "    idf_values = {}\n",
        "    num_documents = len(documents)\n",
        "    for term in vocabulary:\n",
        "        count = sum(term in document for document in documents)\n",
        "        idf_values[term] = math.log(num_documents / count, 2) \n",
        "    return idf_values\n",
        "\n",
        "idf_values = idf(vocabulary, documents)\n",
        "[idf_values[key] for key in vocabulary[:5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB6PSiMPjFFX"
      },
      "source": [
        "3. Compare the results with the reference implementation of scikit-learn library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7fK6QXwjHB1",
        "outputId": "f8bdc4bc-51c9-479f-8063-ced51a41849e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 617)\t1\n",
            "  (0, 6120)\t1\n",
            "  (0, 6614)\t1\n",
            "  (0, 5674)\t1\n",
            "  (0, 6187)\t1\n",
            "  (0, 3209)\t1\n",
            "  (0, 3203)\t1\n",
            "  (0, 1462)\t1\n",
            "  (0, 7107)\t1\n",
            "  (1, 6614)\t1\n",
            "  (1, 3203)\t1\n",
            "  (1, 1462)\t1\n",
            "  (1, 2667)\t1\n",
            "  (1, 7259)\t1\n",
            "  (1, 4285)\t1\n",
            "  (1, 1881)\t1\n",
            "  (1, 2392)\t1\n",
            "  (1, 6575)\t1\n",
            "  (1, 3489)\t1\n",
            "  (1, 403)\t1\n",
            "  (1, 4846)\t1\n",
            "  (1, 3278)\t1\n",
            "  (1, 897)\t1\n",
            "  (1, 4751)\t1\n",
            "  (1, 4936)\t1\n",
            "  :\t:\n",
            "  (2817, 2740)\t1\n",
            "  (2817, 3257)\t1\n",
            "  (2817, 5817)\t1\n",
            "  (2817, 3258)\t1\n",
            "  (2817, 1162)\t1\n",
            "  (2817, 7201)\t1\n",
            "  (2817, 5655)\t1\n",
            "  (2817, 7123)\t1\n",
            "  (2817, 4655)\t1\n",
            "  (2817, 5409)\t1\n",
            "  (2818, 3489)\t1\n",
            "  (2818, 6612)\t1\n",
            "  (2818, 6740)\t1\n",
            "  (2818, 6658)\t1\n",
            "  (2818, 441)\t1\n",
            "  (2818, 7272)\t1\n",
            "  (2818, 733)\t1\n",
            "  (2818, 4192)\t2\n",
            "  (2818, 924)\t1\n",
            "  (2818, 5190)\t1\n",
            "  (2818, 6907)\t1\n",
            "  (2818, 5056)\t1\n",
            "  (2818, 6144)\t1\n",
            "  (2818, 3282)\t1\n",
            "  (2818, 5168)\t1\n",
            "['00' '000' '01' ... 'zyfazr2bb2' 'zyv4h85o' 'zzijxxyy']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "\n",
        "stemmer = FrenchStemmer()\n",
        "analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))\n",
        "\n",
        "# Convert the list of documents into a single string\n",
        "corpus = [' '.join(doc) for doc in documents]\n",
        "\n",
        "stem_vectorizer = CountVectorizer(analyzer=stemmed_words)\n",
        "print(stem_vectorizer.fit_transform(corpus))\n",
        "print(stem_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3txiSyvk0e-",
        "outputId": "0f432f2e-8fc2-4736-82ef-7da393f3fe81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('http', 163.54366542841234), ('https', 151.85039944652075), ('rt', 112.61998731390989), ('tesla', 95.96401470715628), ('xe2', 88.20944486346477)]\n",
            "testla 0.3495243100660956\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "tfidf = TfidfVectorizer (analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english', max_features=500)\n",
        "\n",
        "features=tfidf.fit(original_documents)\n",
        "corpus_tf_idf = tfidf.transform (original_documents)\n",
        "\n",
        "sum_words = corpus_tf_idf.sum(axis=0)\n",
        "words_freq = [(word, sum_words [0, idx]) for word, idx in tfidf.vocabulary_.items()]\n",
        "print (sorted (words_freq, key = lambda x: x[1], reverse=True)[:5])\n",
        "print('testla', corpus_tf_idf [1, features.vocabulary_['tesla']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq_Lcju_lol8"
      },
      "source": [
        "4. Apply TF-IDF for information retrieval \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "dtqtZ9uZlo-c",
        "outputId": "bd15d7fe-b143-424d-916b-e246b2d9ea68"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-9d6b9465bc56>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"tesla nasa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdocument_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0msearch_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'words_freq' is not defined"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "def cosine_similarity (v1, v2):\n",
        "\n",
        "  sumxx, sumxy, sumyy = 0, 0, 0\n",
        "  for i in range(len(v1)):\n",
        "    x = v[i]; \n",
        "    y = v2[i]\n",
        "    sumxx += x*x\n",
        "    sumyy += y*y\n",
        "    sumxy += x*y\n",
        "  if sumxy == 0:\n",
        "    result = 0\n",
        "  else:\n",
        "    result = sumxy/math.sqrt(sumxx*sumyy)\n",
        "  return result\n",
        "\n",
        "def search_vec (query, k, vocabulary, stemmer, document_vectors, original_documents):\n",
        "  q= query.split()\n",
        "  q = [stemmer.stem (w) for w in q]\n",
        "  query_vector = vectorize(q, vocabulary, idf)\n",
        "    # TODO: rank the documents by cosine similarity\n",
        "  scores = [[cosine_similarity (query_vector, document_vectors[d]), d] for d in range(len(document_vectors))] \n",
        "  scores.sort(key=lambda x: -x[0])\n",
        "\n",
        "  print('Top-{0} documents'.format(k))\n",
        "  for i in range(k):\n",
        "     print(i, original_documents [scores [i][1]])\n",
        "\n",
        "query= \"tesla nasa\"\n",
        "stemmer = PorterStemmer()\n",
        "document_vectors=words_freq\n",
        "search_vec(query, 5, vocabulary, stemmer, document_vectors, original_documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7izliSOroyyH"
      },
      "source": [
        "II. Text Processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvcVJN4To1pS"
      },
      "source": [
        "1. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMfRPWKyo9gZ",
        "outputId": "f267b650-c8eb-4830-8f7a-bd05153694a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt') #Run this line one time to get the resource\n",
        "nltk.download('stopwords') #Run this line one time to get the resource\n",
        "nltk.download('wordnet') #Run this line one time to get the resource\n",
        "nltk.download('averaged_perceptron_tagger') #Run this line one time to get the resource\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNCH1wqco-r9"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab/coldplay.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1xBk3lL3ps6c",
        "outputId": "d95b4731-3058-488b-d2f6-af9b687d9f87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81469232-dd54-4ccb-9644-d164fb0728b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>Link</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Another's Arms</td>\n",
              "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
              "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Bigger Stronger</td>\n",
              "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
              "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Daylight</td>\n",
              "      <td>/c/coldplay/daylight_20032625.html</td>\n",
              "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Everglow</td>\n",
              "      <td>/c/coldplay/everglow_21104546.html</td>\n",
              "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Every Teardrop Is A Waterfall</td>\n",
              "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
              "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Hymn For The Weekend</td>\n",
              "      <td>/c/coldplay/hymn+for+the+weekend_21104544.html</td>\n",
              "      <td>Oh, angel sent from up above  \\nYou know you m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>In My Place</td>\n",
              "      <td>/c/coldplay/in+my+place_20032629.html</td>\n",
              "      <td>In my place, in my place  \\nWere lines that I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Ink</td>\n",
              "      <td>/c/coldplay/ink_21082518.html</td>\n",
              "      <td>Got a tattoo that says \"2gether thru life\"  \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Ladder To The Sun</td>\n",
              "      <td>/c/coldplay/ladder+to+the+sun_20232934.html</td>\n",
              "      <td>From the very start  \\nIt came apart  \\nIt bro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Coldplay</td>\n",
              "      <td>Lost</td>\n",
              "      <td>/c/coldplay/lost_20743853.html</td>\n",
              "      <td>Just because I'm losing  \\nDoesn't mean I'm lo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81469232-dd54-4ccb-9644-d164fb0728b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81469232-dd54-4ccb-9644-d164fb0728b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81469232-dd54-4ccb-9644-d164fb0728b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Artist                           Song  \\\n",
              "0    Coldplay                 Another's Arms   \n",
              "1    Coldplay                Bigger Stronger   \n",
              "2    Coldplay                       Daylight   \n",
              "3    Coldplay                       Everglow   \n",
              "4    Coldplay  Every Teardrop Is A Waterfall   \n",
              "..        ...                            ...   \n",
              "115  Coldplay           Hymn For The Weekend   \n",
              "116  Coldplay                    In My Place   \n",
              "117  Coldplay                            Ink   \n",
              "118  Coldplay              Ladder To The Sun   \n",
              "119  Coldplay                           Lost   \n",
              "\n",
              "                                                  Link  \\\n",
              "0              /c/coldplay/anothers+arms_21079526.html   \n",
              "1            /c/coldplay/bigger+stronger_20032648.html   \n",
              "2                   /c/coldplay/daylight_20032625.html   \n",
              "3                   /c/coldplay/everglow_21104546.html   \n",
              "4    /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
              "..                                                 ...   \n",
              "115     /c/coldplay/hymn+for+the+weekend_21104544.html   \n",
              "116              /c/coldplay/in+my+place_20032629.html   \n",
              "117                      /c/coldplay/ink_21082518.html   \n",
              "118        /c/coldplay/ladder+to+the+sun_20232934.html   \n",
              "119                     /c/coldplay/lost_20743853.html   \n",
              "\n",
              "                                                Lyrics  \n",
              "0    Late night watching tv  \\nUsed to be you here ...  \n",
              "1    I want to be bigger stronger drive a faster ca...  \n",
              "2    To my surprise, and my delight  \\nI saw sunris...  \n",
              "3    Oh, they say people come  \\nThey say people go...  \n",
              "4    I turn the music up, I got my records on  \\nI ...  \n",
              "..                                                 ...  \n",
              "115  Oh, angel sent from up above  \\nYou know you m...  \n",
              "116  In my place, in my place  \\nWere lines that I ...  \n",
              "117  Got a tattoo that says \"2gether thru life\"  \\n...  \n",
              "118  From the very start  \\nIt came apart  \\nIt bro...  \n",
              "119  Just because I'm losing  \\nDoesn't mean I'm lo...  \n",
              "\n",
              "[120 rows x 4 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kDT-XVCp8mH",
        "outputId": "c2a30be9-2bb5-47e2-ce2e-f3bb9db5cf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Artist  120 non-null    object\n",
            " 1   Song    120 non-null    object\n",
            " 2   Link    120 non-null    object\n",
            " 3   Lyrics  120 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 3.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clecBSz_qzgw",
        "outputId": "4fcde08f-1b23-42b3-8052-9bdac878fda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I turn the music up, I got my records on  \n",
            "I shut the world outside until the lights come on  \n",
            "Maybe the streets alight, maybe the trees are gone  \n",
            "I feel my heart start beating to my favourite song  \n",
            "  \n",
            "And all the kids they dance, all the kids all night  \n",
            "Until Monday morning feels another life  \n",
            "I turn the music up  \n",
            "I'm on a roll this time  \n",
            "And heaven is in sight  \n",
            "  \n",
            "I turn the music up, I got my records on  \n",
            "From underneath the rubble sing a rebel song  \n",
            "Don't want to see another generation drop  \n",
            "I'd rather be a comma than a full stop  \n",
            "  \n",
            "Maybe I'm in the black, maybe I'm on my knees  \n",
            "Maybe I'm in the gap between the two trapezes  \n",
            "But my heart is beating and my pulses start  \n",
            "Cathedrals in my heart  \n",
            "  \n",
            "As we saw oh this light I swear you, emerge blinking into  \n",
            "To tell me it's alright  \n",
            "As we soar walls, every siren is a symphony  \n",
            "And every tear's a waterfall  \n",
            "Is a waterfall  \n",
            "Oh  \n",
            "Is a waterfall  \n",
            "Oh oh oh  \n",
            "Is a is a waterfall  \n",
            "Every tear  \n",
            "Is a waterfall  \n",
            "Oh oh oh  \n",
            "  \n",
            "So you can hurt, hurt me bad  \n",
            "But still I'll raise the flag  \n",
            "  \n",
            "Oh  \n",
            "It was a wa wa wa wa wa-aterfall  \n",
            "A wa wa wa wa wa-aterfall  \n",
            "  \n",
            "Every tear  \n",
            "Every tear  \n",
            "Every teardrop is a waterfall  \n",
            "  \n",
            "Every tear  \n",
            "Every tear  \n",
            "Every teardrop is a waterfall  \n",
            "  \n",
            "Every tear  \n",
            "Every tear  \n",
            "Every teardrop is a waterfall\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "song_title = 'Every Teardrop Is A Waterfall'\n",
        "lyrics = df.loc[df['Song'] == song_title, 'Lyrics'].values[0]\n",
        "print(lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycBcYNwwq-T5",
        "outputId": "d543e24d-2800-403b-eb58-d75365e80d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'turn', 'the', 'music', 'up', ',', 'I', 'got', 'my', 'records', 'on', 'I', 'shut', 'the', 'world', 'outside', 'until', 'the', 'lights', 'come', 'on', 'Maybe', 'the', 'streets', 'alight', ',', 'maybe', 'the', 'trees', 'are', 'gone', 'I', 'feel', 'my', 'heart', 'start', 'beating', 'to', 'my', 'favourite', 'song', 'And', 'all', 'the', 'kids', 'they', 'dance', ',', 'all', 'the', 'kids', 'all', 'night', 'Until', 'Monday', 'morning', 'feels', 'another', 'life', 'I', 'turn', 'the', 'music', 'up', 'I', \"'m\", 'on', 'a', 'roll', 'this', 'time', 'And', 'heaven', 'is', 'in', 'sight', 'I', 'turn', 'the', 'music', 'up', ',', 'I', 'got', 'my', 'records', 'on', 'From', 'underneath', 'the', 'rubble', 'sing', 'a', 'rebel', 'song', 'Do', \"n't\", 'want', 'to', 'see', 'another', 'generation', 'drop', 'I', \"'d\", 'rather', 'be', 'a', 'comma', 'than', 'a', 'full', 'stop', 'Maybe', 'I', \"'m\", 'in', 'the', 'black', ',', 'maybe', 'I', \"'m\", 'on', 'my', 'knees', 'Maybe', 'I', \"'m\", 'in', 'the', 'gap', 'between', 'the', 'two', 'trapezes', 'But', 'my', 'heart', 'is', 'beating', 'and', 'my', 'pulses', 'start', 'Cathedrals', 'in', 'my', 'heart', 'As', 'we', 'saw', 'oh', 'this', 'light', 'I', 'swear', 'you', ',', 'emerge', 'blinking', 'into', 'To', 'tell', 'me', 'it', \"'s\", 'alright', 'As', 'we', 'soar', 'walls', ',', 'every', 'siren', 'is', 'a', 'symphony', 'And', 'every', 'tear', \"'s\", 'a', 'waterfall', 'Is', 'a', 'waterfall', 'Oh', 'Is', 'a', 'waterfall', 'Oh', 'oh', 'oh', 'Is', 'a', 'is', 'a', 'waterfall', 'Every', 'tear', 'Is', 'a', 'waterfall', 'Oh', 'oh', 'oh', 'So', 'you', 'can', 'hurt', ',', 'hurt', 'me', 'bad', 'But', 'still', 'I', \"'ll\", 'raise', 'the', 'flag', 'Oh', 'It', 'was', 'a', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'A', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "# Tokenize the lyrics\n",
        "from nltk import word_tokenize\n",
        "words = word_tokenize(lyrics)\n",
        "print(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mta30M25rBMQ",
        "outputId": "8759fec1-6e60-4f36-9d68-30f8ed7b2e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'turn', 'the', 'music', 'up', 'I', 'got', 'my', 'records', 'on', 'I', 'shut', 'the', 'world', 'outside', 'until', 'the', 'lights', 'come', 'on', 'Maybe', 'the', 'streets', 'alight', 'maybe', 'the', 'trees', 'are', 'gone', 'I', 'feel', 'my', 'heart', 'start', 'beating', 'to', 'my', 'favourite', 'song', 'And', 'all', 'the', 'kids', 'they', 'dance', 'all', 'the', 'kids', 'all', 'night', 'Until', 'Monday', 'morning', 'feels', 'another', 'life', 'I', 'turn', 'the', 'music', 'up', 'I', \"'m\", 'on', 'a', 'roll', 'this', 'time', 'And', 'heaven', 'is', 'in', 'sight', 'I', 'turn', 'the', 'music', 'up', 'I', 'got', 'my', 'records', 'on', 'From', 'underneath', 'the', 'rubble', 'sing', 'a', 'rebel', 'song', 'Do', \"n't\", 'want', 'to', 'see', 'another', 'generation', 'drop', 'I', \"'d\", 'rather', 'be', 'a', 'comma', 'than', 'a', 'full', 'stop', 'Maybe', 'I', \"'m\", 'in', 'the', 'black', 'maybe', 'I', \"'m\", 'on', 'my', 'knees', 'Maybe', 'I', \"'m\", 'in', 'the', 'gap', 'between', 'the', 'two', 'trapezes', 'But', 'my', 'heart', 'is', 'beating', 'and', 'my', 'pulses', 'start', 'Cathedrals', 'in', 'my', 'heart', 'As', 'we', 'saw', 'oh', 'this', 'light', 'I', 'swear', 'you', 'emerge', 'blinking', 'into', 'To', 'tell', 'me', 'it', \"'s\", 'alright', 'As', 'we', 'soar', 'walls', 'every', 'siren', 'is', 'a', 'symphony', 'And', 'every', 'tear', \"'s\", 'a', 'waterfall', 'Is', 'a', 'waterfall', 'Oh', 'Is', 'a', 'waterfall', 'Oh', 'oh', 'oh', 'Is', 'a', 'is', 'a', 'waterfall', 'Every', 'tear', 'Is', 'a', 'waterfall', 'Oh', 'oh', 'oh', 'So', 'you', 'can', 'hurt', 'hurt', 'me', 'bad', 'But', 'still', 'I', \"'ll\", 'raise', 'the', 'flag', 'Oh', 'It', 'was', 'a', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'A', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'is', 'a', 'waterfall']\n"
          ]
        }
      ],
      "source": [
        "tokens_without_punctuation = [token for token in words if token not in string.punctuation]\n",
        "\n",
        "print(tokens_without_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWgGp7sgrSjg",
        "outputId": "df8e7ce6-9858-4062-aabb-861e91027851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'turn', 'music', ',', 'I', 'got', 'records', 'I', 'shut', 'world', 'outside', 'lights', 'come', 'Maybe', 'streets', 'alight', ',', 'maybe', 'trees', 'gone', 'I', 'feel', 'heart', 'start', 'beating', 'favourite', 'song', 'And', 'kids', 'dance', ',', 'kids', 'night', 'Until', 'Monday', 'morning', 'feels', 'another', 'life', 'I', 'turn', 'music', 'I', \"'m\", 'roll', 'time', 'And', 'heaven', 'sight', 'I', 'turn', 'music', ',', 'I', 'got', 'records', 'From', 'underneath', 'rubble', 'sing', 'rebel', 'song', 'Do', \"n't\", 'want', 'see', 'another', 'generation', 'drop', 'I', \"'d\", 'rather', 'comma', 'full', 'stop', 'Maybe', 'I', \"'m\", 'black', ',', 'maybe', 'I', \"'m\", 'knees', 'Maybe', 'I', \"'m\", 'gap', 'two', 'trapezes', 'But', 'heart', 'beating', 'pulses', 'start', 'Cathedrals', 'heart', 'As', 'saw', 'oh', 'light', 'I', 'swear', ',', 'emerge', 'blinking', 'To', 'tell', \"'s\", 'alright', 'As', 'soar', 'walls', ',', 'every', 'siren', 'symphony', 'And', 'every', 'tear', \"'s\", 'waterfall', 'Is', 'waterfall', 'Oh', 'Is', 'waterfall', 'Oh', 'oh', 'oh', 'Is', 'waterfall', 'Every', 'tear', 'Is', 'waterfall', 'Oh', 'oh', 'oh', 'So', 'hurt', ',', 'hurt', 'bad', 'But', 'still', 'I', \"'ll\", 'raise', 'flag', 'Oh', 'It', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'A', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        " \n",
        "word_tokens = word_tokenize(lyrics)\n",
        "# converts the words in word_tokens to lower case and then checks whether\n",
        "#they are present in stop_words or not\n",
        "filtered_sentence = [w for w in words if not w.lower() in stop_words]\n",
        "#with no lower case conversion\n",
        "filtered_sentence = []\n",
        " \n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        " \n",
        "print(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jrlULdhrVtZ",
        "outputId": "fd8be6d1-db37-4200-a65e-b54259f7b52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'turn', 'music', ',', 'I', 'got', 'record', 'I', 'shut', 'world', 'outside', 'light', 'come', 'Maybe', 'street', 'alight', ',', 'maybe', 'tree', 'gone', 'I', 'feel', 'heart', 'start', 'beating', 'favourite', 'song', 'And', 'kid', 'dance', ',', 'kid', 'night', 'Until', 'Monday', 'morning', 'feel', 'another', 'life', 'I', 'turn', 'music', 'I', \"'m\", 'roll', 'time', 'And', 'heaven', 'sight', 'I', 'turn', 'music', ',', 'I', 'got', 'record', 'From', 'underneath', 'rubble', 'sing', 'rebel', 'song', 'Do', \"n't\", 'want', 'see', 'another', 'generation', 'drop', 'I', \"'d\", 'rather', 'comma', 'full', 'stop', 'Maybe', 'I', \"'m\", 'black', ',', 'maybe', 'I', \"'m\", 'knee', 'Maybe', 'I', \"'m\", 'gap', 'two', 'trapeze', 'But', 'heart', 'beating', 'pulse', 'start', 'Cathedrals', 'heart', 'As', 'saw', 'oh', 'light', 'I', 'swear', ',', 'emerge', 'blinking', 'To', 'tell', \"'s\", 'alright', 'As', 'soar', 'wall', ',', 'every', 'siren', 'symphony', 'And', 'every', 'tear', \"'s\", 'waterfall', 'Is', 'waterfall', 'Oh', 'Is', 'waterfall', 'Oh', 'oh', 'oh', 'Is', 'waterfall', 'Every', 'tear', 'Is', 'waterfall', 'Oh', 'oh', 'oh', 'So', 'hurt', ',', 'hurt', 'bad', 'But', 'still', 'I', \"'ll\", 'raise', 'flag', 'Oh', 'It', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'A', 'wa', 'wa', 'wa', 'wa', 'wa-aterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall', 'Every', 'tear', 'Every', 'tear', 'Every', 'teardrop', 'waterfall']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_sentence]\n",
        "print(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdXSGwKZrheh",
        "outputId": "53f201d9-ef9d-44bb-9c09-eba73760a335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('I', 'PRP'), ('turn', 'VBP'), ('music', 'NN'), (',', ','), ('I', 'PRP'), ('got', 'VBD'), ('record', 'NN'), ('I', 'PRP'), ('shut', 'VBP'), ('world', 'NN'), ('outside', 'IN'), ('light', 'JJ'), ('come', 'VBP'), ('Maybe', 'NNP'), ('street', 'NN'), ('alight', 'NN'), (',', ','), ('maybe', 'RB'), ('tree', 'IN'), ('gone', 'VBN'), ('I', 'PRP'), ('feel', 'VBP'), ('heart', 'NN'), ('start', 'NN'), ('beating', 'VBG'), ('favourite', 'NN'), ('song', 'NN'), ('And', 'CC'), ('kid', 'NN'), ('dance', 'NN'), (',', ','), ('kid', 'VB'), ('night', 'NN'), ('Until', 'IN'), ('Monday', 'NNP'), ('morning', 'NN'), ('feel', 'NN'), ('another', 'DT'), ('life', 'NN'), ('I', 'PRP'), ('turn', 'VBP'), ('music', 'NN'), ('I', 'PRP'), (\"'m\", 'VBP'), ('roll', 'JJ'), ('time', 'NN'), ('And', 'CC'), ('heaven', 'JJ'), ('sight', 'NN'), ('I', 'PRP'), ('turn', 'VBP'), ('music', 'NN'), (',', ','), ('I', 'PRP'), ('got', 'VBD'), ('record', 'NN'), ('From', 'IN'), ('underneath', 'JJ'), ('rubble', 'JJ'), ('sing', 'VBG'), ('rebel', 'NN'), ('song', 'NN'), ('Do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('see', 'VB'), ('another', 'DT'), ('generation', 'NN'), ('drop', 'NN'), ('I', 'PRP'), (\"'d\", 'MD'), ('rather', 'RB'), ('comma', 'VB'), ('full', 'JJ'), ('stop', 'NN'), ('Maybe', 'NNP'), ('I', 'PRP'), (\"'m\", 'VBP'), ('black', 'JJ'), (',', ','), ('maybe', 'RB'), ('I', 'PRP'), (\"'m\", 'VBP'), ('knee', 'JJ'), ('Maybe', 'NNP'), ('I', 'PRP'), (\"'m\", 'VBP'), ('gap', 'JJ'), ('two', 'CD'), ('trapeze', 'NN'), ('But', 'CC'), ('heart', 'NN'), ('beating', 'NN'), ('pulse', 'JJ'), ('start', 'NN'), ('Cathedrals', 'NNP'), ('heart', 'NN'), ('As', 'IN'), ('saw', 'JJ'), ('oh', 'IN'), ('light', 'JJ'), ('I', 'PRP'), ('swear', 'VBP'), (',', ','), ('emerge', 'VBP'), ('blinking', 'VBG'), ('To', 'TO'), ('tell', 'VB'), (\"'s\", 'POS'), ('alright', 'NN'), ('As', 'IN'), ('soar', 'NN'), ('wall', 'NN'), (',', ','), ('every', 'DT'), ('siren', 'NN'), ('symphony', 'NN'), ('And', 'CC'), ('every', 'DT'), ('tear', 'NN'), (\"'s\", 'POS'), ('waterfall', 'NN'), ('Is', 'VBZ'), ('waterfall', 'JJ'), ('Oh', 'NNP'), ('Is', 'NNP'), ('waterfall', 'JJ'), ('Oh', 'NNP'), ('oh', 'MD'), ('oh', 'VB'), ('Is', 'NNP'), ('waterfall', 'JJ'), ('Every', 'NNP'), ('tear', 'NN'), ('Is', 'VBZ'), ('waterfall', 'JJ'), ('Oh', 'NNP'), ('oh', 'MD'), ('oh', 'VB'), ('So', 'NNP'), ('hurt', 'FW'), (',', ','), ('hurt', 'VBN'), ('bad', 'JJ'), ('But', 'CC'), ('still', 'RB'), ('I', 'PRP'), (\"'ll\", 'MD'), ('raise', 'VB'), ('flag', 'NN'), ('Oh', 'IN'), ('It', 'PRP'), ('wa', 'VBZ'), ('wa', 'JJ'), ('wa', 'JJ'), ('wa', 'NN'), ('wa-aterfall', 'NN'), ('A', 'NNP'), ('wa', 'NN'), ('wa', 'NN'), ('wa', 'NN'), ('wa', 'VBD'), ('wa-aterfall', 'JJ'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('teardrop', 'NN'), ('waterfall', 'NN'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('teardrop', 'NN'), ('waterfall', 'NN'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('tear', 'NN'), ('Every', 'NNP'), ('teardrop', 'NN'), ('waterfall', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import pos_tag\n",
        "pos_tags = nltk.pos_tag(lemmatized_tokens)\n",
        "\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gYpine7sNKN"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    output = np.asarray(pos_tag)\n",
        "    for i in range(len(pos_tag)):\n",
        "        if pos_tag[i][1].startswith('J'):\n",
        "            output[i][1] = wordnet.ADJ\n",
        "        elif pos_tag[i][1].startswith('V'):\n",
        "            output[i][1] = wordnet.VERB\n",
        "        elif pos_tag[i][1].startswith('R'):\n",
        "            output[i][1] = wordnet.ADV\n",
        "        else:\n",
        "            output[i][1] = wordnet.NOUN\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFb2W_zPbWpz"
      },
      "source": [
        "2. Bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q4X2_nObXK5"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ3GVk76beZr"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab/coldplay.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOAhOO3ubk4z",
        "outputId": "76fbfa2c-3a35-4f3f-c970-bf13f0a967a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Artist  120 non-null    object\n",
            " 1   Song    120 non-null    object\n",
            " 2   Link    120 non-null    object\n",
            " 3   Lyrics  120 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 3.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYYwPGedbl_M",
        "outputId": "63d4429b-65a5-4d92-ff57-d0a6c2e6601e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(120, 1776)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "bow = vectorizer.fit_transform(df['Lyrics'])\n",
        "\n",
        "print( bow.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T48K7TtmcHl7",
        "outputId": "1c7adbe8-1761-4c13-e00b-5d09f59e07c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89a20bc6-5cd3-48d6-a8c9-0e106c97c409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>2000</th>\n",
              "      <th>2gether</th>\n",
              "      <th>76543</th>\n",
              "      <th>aaaaaah</th>\n",
              "      <th>aaaaah</th>\n",
              "      <th>aaaah</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>achin</th>\n",
              "      <th>...</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>yourself</th>\n",
              "      <th>yuletide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 1776 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89a20bc6-5cd3-48d6-a8c9-0e106c97c409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89a20bc6-5cd3-48d6-a8c9-0e106c97c409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89a20bc6-5cd3-48d6-a8c9-0e106c97c409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     10  2000  2gether  76543  aaaaaah  aaaaah  aaaah  about  above  achin  \\\n",
              "0     0     0        0      0        0       0      0      0      0      0   \n",
              "1     0     0        0      0        0       0      0      0      0      0   \n",
              "2     0     0        0      0        0       0      0      0      0      0   \n",
              "3     0     0        0      0        0       0      0      0      0      0   \n",
              "4     0     0        0      0        0       0      0      0      0      0   \n",
              "..   ..   ...      ...    ...      ...     ...    ...    ...    ...    ...   \n",
              "115   0     0        0      0        0       0      0      1      2      0   \n",
              "116   0     0        0      0        0       0      0      0      0      0   \n",
              "117   0     0        1      0        0       0      0      0      0      0   \n",
              "118   0     0        0      0        0       0      0      0      0      0   \n",
              "119   0     0        0      0        0       0      0      0      0      0   \n",
              "\n",
              "     ...  yellow  yes  yesterday  yet  you  young  your  yours  yourself  \\\n",
              "0    ...       0    0          0    0    4      0     4      0         2   \n",
              "1    ...       0    0          0    0    0      0     0      0         0   \n",
              "2    ...       0    0          0    0    0      0     0      0         0   \n",
              "3    ...       0    0          0    0   16      0     0      0         0   \n",
              "4    ...       0    0          0    0    2      0     0      0         0   \n",
              "..   ...     ...  ...        ...  ...  ...    ...   ...    ...       ...   \n",
              "115  ...       0    0          0    0    5      0     3      0         0   \n",
              "116  ...       0    0          0    0    9      0     0      0         0   \n",
              "117  ...       0    0          0    0    7      0     4      0         0   \n",
              "118  ...       0    0          0    0   16      0     1      0         0   \n",
              "119  ...       0    0          0    0    5      0     0      0         0   \n",
              "\n",
              "     yuletide  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "..        ...  \n",
              "115         0  \n",
              "116         0  \n",
              "117         0  \n",
              "118         0  \n",
              "119         0  \n",
              "\n",
              "[120 rows x 1776 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dataframe from the BOW matrix and feature names\n",
        "bow_df = pd.DataFrame(bow.toarray(), columns=feature_names)\n",
        "\n",
        "bow_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bJAiXbcMchh0",
        "outputId": "5abbc03b-0064-4b33-8af8-9c1015c1b762"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum_bow = bow_df.sum()\n",
        "sum_bow.idxmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLMPgOJgc0hr",
        "outputId": "25c946ff-3a4d-4e0e-fca5-5552d13ba936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you    994\n",
            "the    777\n",
            "and    650\n",
            "to     481\n",
            "it     458\n",
            "oh     334\n",
            "in     318\n",
            "me     314\n",
            "my     288\n",
            "on     285\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "word_counts = bow_df.sum()\n",
        "top_10_words = word_counts.nlargest(10)\n",
        "\n",
        "# Print the top 10 words\n",
        "print(top_10_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r433ez-bXd2"
      },
      "source": [
        "III. Text Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uVQSMwabZe-"
      },
      "source": [
        "1.. Similarity metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w91FJfKdBQQ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWjb3YjRdbJs"
      },
      "outputs": [],
      "source": [
        "A = \"Outside the classroom, Stallman pursued his studies with even more diligence, rushing off to fulfill his laboratory-assistant duties at Rockefeller University during the week and dodging the Vietnam protesters on his way to Saturday school at Columbia. It was there, while the rest of the Science Honors Program students sat around discussing their college choices, that Stallman finally took a moment to participate in the preclass bull session.\"\n",
        "B = \"To facilitate the process, AI Lab hackers had built a system that displayed both the source and display modes on a split screen. Despite this innovative hack, switching from mode to mode was still a nuisance.\"\n",
        "C = \"With no dorm and no dancing, Stallman's social universe imploded. Like an astronaut experiencing the aftereffects of zero-gravity, Stallman found that his ability to interact with nonhackers, especially female nonhackers, had atrophied significantly. After 16 weeks in the AI Lab, the self confidence he'd been quietly accumulating during his 4 years at Harvard was virtually gone.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRv4LwDWdbru",
        "outputId": "e13ece81-f3d9-47c9-98c1-61eb8562e97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jaccard Similarity between A and B: 0.08641975308641975\n",
            "Jaccard Similarity between A and C: 0.12631578947368421\n",
            "Jaccard Similarity between B and C: 0.0945945945945946\n"
          ]
        }
      ],
      "source": [
        "set_A = set(A.lower().split())\n",
        "set_B = set(B.lower().split())\n",
        "set_C = set(C.lower().split())\n",
        "\n",
        "# Compute the intersection and union\n",
        "intersection_AB = len(set_A.intersection(set_B))\n",
        "union_AB = len(set_A.union(set_B))\n",
        "\n",
        "intersection_AC = len(set_A.intersection(set_C))\n",
        "union_AC = len(set_A.union(set_C))\n",
        "\n",
        "intersection_BC = len(set_B.intersection(set_C))\n",
        "union_BC = len(set_B.union(set_C))\n",
        "\n",
        "# Compute and print the Jaccard Similarity\n",
        "jaccard_AB = intersection_AB / union_AB\n",
        "jaccard_AC = intersection_AC / union_AC\n",
        "jaccard_BC = intersection_BC / union_BC\n",
        "\n",
        "print(\"Jaccard Similarity between A and B:\", jaccard_AB)\n",
        "print(\"Jaccard Similarity between A and C:\", jaccard_AC)\n",
        "print(\"Jaccard Similarity between B and C:\", jaccard_BC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-kD8RGed28v",
        "outputId": "fe37b455-8770-44a4-ade6-3ca15ffba0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cos(A, B): [[0.1679327]]\n",
            "cos(B, C): [[0.13618963]]\n",
            "cos(A, C): [[0.2850296]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Compute TF-IDF for sentences A, B, and C\n",
        "tfidf = vectorizer.fit_transform([A, B, C])\n",
        "\n",
        "# Calculate cosine similarities\n",
        "cosine_sim_AB = cosine_similarity(tfidf[0], tfidf[1])\n",
        "cosine_sim_BC = cosine_similarity(tfidf[1], tfidf[2])\n",
        "cosine_sim_AC = cosine_similarity(tfidf[0], tfidf[2])\n",
        "\n",
        "# Print cosine similarities\n",
        "print(\"cos(A, B):\", cosine_sim_AB)\n",
        "print(\"cos(B, C):\", cosine_sim_BC)\n",
        "print(\"cos(A, C):\", cosine_sim_AC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSP3fJuaTI6m"
      },
      "source": [
        "2. TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXj5laIZTLUm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5hHRV7qTeIc"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab/headlines.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dq7-nFU8TidE",
        "outputId": "27310a87-528f-4e68-cf24-3da592184144"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-659e97be-041a-4312-b3e8-08af7ac5d789\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20170721</td>\n",
              "      <td>algorithms can make decisions on behalf of fed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20170721</td>\n",
              "      <td>andrew forrests fmg to appeal pilbara native t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20170721</td>\n",
              "      <td>a rural mural in thallan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20170721</td>\n",
              "      <td>australia church risks becoming haven for abusers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20170721</td>\n",
              "      <td>australian company usgfx embroiled in shanghai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-659e97be-041a-4312-b3e8-08af7ac5d789')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-659e97be-041a-4312-b3e8-08af7ac5d789 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-659e97be-041a-4312-b3e8-08af7ac5d789');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20170721  algorithms can make decisions on behalf of fed...\n",
              "1      20170721  andrew forrests fmg to appeal pilbara native t...\n",
              "2      20170721                           a rural mural in thallan\n",
              "3      20170721  australia church risks becoming haven for abusers\n",
              "4      20170721  australian company usgfx embroiled in shanghai..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFA-2UsCTkhS",
        "outputId": "700f1221-ee02-40cd-f724-bae17b15ba06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1999 entries, 0 to 1998\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   publish_date   1999 non-null   int64 \n",
            " 1   headline_text  1999 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 31.4+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdFY6X1fUFAA",
        "outputId": "f8726e5c-d6fc-43bc-b05e-49defb220d5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "df['tokens'] = df['headline_text'].apply(lambda x: word_tokenize(x))\n",
        "\n",
        "# Remove punctuation\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token not in string.punctuation])\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token.lower() not in stop_words])\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
        "\n",
        "# Join tokens back into a single string\n",
        "df['Stem'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JZYxcFzU1kQ",
        "outputId": "3a8016d7-d59f-4377-9830-8d97f805c59f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         [algorithm, make, decis, behalf, feder, minist]\n",
              "1       [andrew, forrest, fmg, appeal, pilbara, nativ,...\n",
              "2                                 [rural, mural, thallan]\n",
              "3                  [australia, church, risk, becom, abus]\n",
              "4       [australian, compani, usgfx, embroil, shanghai...\n",
              "                              ...                        \n",
              "1994    [constitut, avenu, win, top, prize, act, archi...\n",
              "1995                         [dark, mofo, number, crunch]\n",
              "1996    [david, petraeu, say, australia, must, firm, s...\n",
              "1997    [driverless, car, australia, face, challeng, r...\n",
              "1998               [drug, compani, criticis, price, hike]\n",
              "Name: tokens, Length: 1999, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tokens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr29DS9VWTHl",
        "outputId": "a3cd47db-227b-41d7-c250-da63823d2ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1999, 4271)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "\n",
        "vectorizer.fit(df['tokens'])\n",
        "bow = vectorizer.transform(df['tokens'])\n",
        "\n",
        "print(bow.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt3oEkAAYGGX",
        "outputId": "677877db-97de-4618-af84-e42665007e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.3943827  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.24444796 0.12987231 0.10011226 0.21470886 0.40884261 0.29023513\n",
            " 0.12972179 0.23484967 0.34095845 0.         0.15309538 0.18376484\n",
            " 0.32930567 0.08609939 0.08749485 0.         0.         0.16659404\n",
            " 0.18357889 0.17297874 0.         0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
        "\n",
        "vectorizer.fit(df['Stem'])\n",
        "\n",
        "\n",
        "tfidf = vectorizer.transform(df['Stem'])\n",
        "\n",
        "tfidf_array = tfidf.toarray()\n",
        "\n",
        "all_zeros = (tfidf_array == 0).all()\n",
        "\n",
        "if not all_zeros:\n",
        "    print(tfidf_array[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuNuWy_eYmTw",
        "outputId": "c8d05f61-52d9-43b0-b876-97de80d1510e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words with the highest average TF-IDF:\n",
            "australia 0.009983014998891405\n",
            "australian 0.00969733014866161\n",
            "new 0.008703107457097207\n",
            "polic 0.0077360592047481126\n",
            "say 0.007540459757782178\n",
            "trump 0.006840891998202155\n",
            "man 0.006548453421337382\n",
            "wa 0.006274671593818188\n",
            "charg 0.006028832916829903\n",
            "sydney 0.0056424159732095394\n",
            "\n",
            "Words with the lowest average TF-IDF:\n",
            "nmfc 0.0001527054029533165\n",
            "coll 0.0001527054029533165\n",
            "melb 0.0001527054029533165\n",
            "haw 0.0001527054029533165\n",
            "adel 0.0001527054029533165\n",
            "syd 0.0001527054029533165\n",
            "gcfc 0.0001527054029533165\n",
            "gw 0.0001527054029533165\n",
            "geel 0.0001527054029533165\n",
            "fabio 0.0001613676677950104\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
        "\n",
        "\n",
        "vectorizer.fit(df['tokens'])\n",
        "\n",
        "\n",
        "tfidf = vectorizer.transform(df['tokens'])\n",
        "\n",
        "\n",
        "tfidf_array = tfidf.toarray()\n",
        "\n",
        "\n",
        "average_tfidf = np.mean(tfidf_array, axis=0)\n",
        "\n",
        "\n",
        "highest_indices = np.argsort(-average_tfidf)[:10]  # Use negative sign for descending order\n",
        "lowest_indices = np.argsort(average_tfidf)[:10]\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "print(\"Words with the highest average TF-IDF:\")\n",
        "for index in highest_indices:\n",
        "    print(feature_names[index], average_tfidf[index])\n",
        "\n",
        "\n",
        "print(\"\\nWords with the lowest average TF-IDF:\")\n",
        "for index in lowest_indices:\n",
        "    print(feature_names[index], average_tfidf[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd-08TYaaRYa"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "\n",
        "documents = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf = vectorizer.fit_transform(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zJTX9gV2aY8",
        "outputId": "89597edb-1392-421d-e7e7-5ac47905e92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words with the highest average TF-IDF:\n",
            "australia 0.009983014998891405\n",
            "australian 0.009729510942149733\n",
            "new 0.008703107457097207\n",
            "polic 0.007736059204748111\n",
            "say 0.007555848605072935\n",
            "trump 0.006840891998202155\n",
            "man 0.006548453421337382\n",
            "wa 0.006274671593818188\n",
            "charg 0.006028832916829904\n",
            "sydney 0.005659788840016151\n",
            "\n",
            "Words with the lowest average TF-IDF:\n",
            "adel 0.0001527054029533165\n",
            "melb 0.0001527054029533165\n",
            "haw 0.0001527054029533165\n",
            "coll 0.0001527054029533165\n",
            "gw 0.0001527054029533165\n",
            "syd 0.0001527054029533165\n",
            "gcfc 0.0001527054029533165\n",
            "nmfc 0.0001527054029533165\n",
            "geel 0.0001527054029533165\n",
            "fabio 0.00016136766779501044\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you have computed the TF-IDF representation and stored it in 'tfidf'\n",
        "\n",
        "# Compute the average TF-IDF values for each feature (word)\n",
        "average_tfidf = np.mean(tfidf.toarray(), axis=0)\n",
        "\n",
        "# Get the indices of the words with the highest and lowest average TF-IDF values\n",
        "highest_indices = np.argsort(-average_tfidf)[:10]  # Use negative sign for descending order\n",
        "lowest_indices = np.argsort(average_tfidf)[:10]\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the words with the highest average TF-IDF values\n",
        "print(\"Words with the highest average TF-IDF:\")\n",
        "for index in highest_indices:\n",
        "    print(feature_names[index], average_tfidf[index])\n",
        "\n",
        "# Print the words with the lowest average TF-IDF values\n",
        "print(\"\\nWords with the lowest average TF-IDF:\")\n",
        "for index in lowest_indices:\n",
        "    print(feature_names[index], average_tfidf[index])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btRM-q6623i5"
      },
      "source": [
        "3. Plagiarism checker \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WrKOYrP239F"
      },
      "outputs": [],
      "source": [
        "file = open('/content/drive/MyDrive/Colab/A1.txt', 'r') \n",
        "A1 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/Asource.txt', 'r') \n",
        "A0 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/B1.txt', 'r') \n",
        "B1 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/Bsource.txt', 'r') \n",
        "B0 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/C1.txt', 'r') \n",
        "C1 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/Csource.txt', 'r') \n",
        "C0 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/D1.txt', 'r') \n",
        "D1 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/D2.txt', 'r') \n",
        "D2 = file.readlines()[0]\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab/Dsource.txt', 'r') \n",
        "D0 = file.readlines()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "6EjZUt1x4x4H",
        "outputId": "760aa3b8-b316-46a4-f1db-fe36f2ed7247"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Descartes has been heralded as the first modern philosopher. He is famous for having made an important connection between geometry and algebra, which allowed for the solving of geometrical problems by way of algebraic equations. He is also famous for having promoted a new conception of matter, which allowed for the accounting of physical phenomena by way of mechanical explanations. However, he is most famous for having written a relatively short work, Meditationes de Prima Philosophia (Meditations On First Philosophy), published in 1641, in which he provides a philosophical groundwork for the possibility of the sciences. (Smith, 2007).\\n'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG8gXJIa4z7L"
      },
      "outputs": [],
      "source": [
        "alldata = [A0, A1, B0, B1, C0, C1, D0, D1, D2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykTo7xJt41E4"
      },
      "outputs": [],
      "source": [
        "#TODO: Compute tf-idf for all documents\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfvect = TfidfVectorizer()\n",
        "tfvect.fit(alldata)\n",
        "\n",
        "\n",
        "tfidf = tfvect.fit_transform(alldata).toarray()\n",
        "# Compute the TF-IDF representation for each document\n",
        "TFIDFA = tfvect.transform([A0, A1]).toarray()\n",
        "TFIDFB = tfvect.transform([B0, B1]).toarray()\n",
        "TFIDFC = tfvect.transform([C0, C1]).toarray()\n",
        "TFIDFD = tfvect.transform([D0, D1, D2]).toarray()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc6l31E_6RMj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute pairwise similarity for document A\n",
        "similarityAA = cosine_similarity(TFIDFA, TFIDFA)\n",
        "\n",
        "# Compute pairwise similarity for document B\n",
        "similarityBB = cosine_similarity(TFIDFB, TFIDFB)\n",
        "\n",
        "# Compute pairwise similarity for document C\n",
        "similarityCC = cosine_similarity(TFIDFC, TFIDFC)\n",
        "\n",
        "# Compute pairwise similarity for document D\n",
        "similarityDD = cosine_similarity(TFIDFD, TFIDFD)\n",
        "\n",
        "# Compute pairwise similarity for all documents\n",
        "similarityAll = cosine_similarity(tfidf, tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRtcv1R66xeT",
        "outputId": "0ea96a58-e93b-4cdb-8118-663a890dbf60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.81898863],\n",
              "       [0.81898863, 1.        ]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarityAA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I06rvNLF6yz7",
        "outputId": "0b8a0f12-7b26-4272-e3f9-1a9449ae842f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.63747903],\n",
              "       [0.63747903, 1.        ]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarityBB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7fdbjxm6z1_",
        "outputId": "186c38f3-32c8-41cc-dcc3-1f3431f5a0d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.85723864],\n",
              "       [0.85723864, 1.        ]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarityCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXSaTh7N61n-",
        "outputId": "c82bb078-b861-41d1-f569-a41f2fedebf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.92754461, 0.45775827],\n",
              "       [0.92754461, 1.        , 0.47179638],\n",
              "       [0.45775827, 0.47179638, 1.        ]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarityDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CkBDNK62pa",
        "outputId": "3dbeeae1-8af5-4bd2-9327-de774e6afeb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.81898863, 0.10748497, 0.12736224, 0.24491604,\n",
              "        0.29501242, 0.2530779 , 0.2146434 , 0.18585492],\n",
              "       [0.81898863, 1.        , 0.10940658, 0.12644471, 0.21239125,\n",
              "        0.25583485, 0.214717  , 0.17937458, 0.16807197],\n",
              "       [0.10748497, 0.10940658, 1.        , 0.63747903, 0.08804551,\n",
              "        0.09372089, 0.08509508, 0.07946359, 0.10627147],\n",
              "       [0.12736224, 0.12644471, 0.63747903, 1.        , 0.08730757,\n",
              "        0.08893992, 0.12527568, 0.1207279 , 0.12910021],\n",
              "       [0.24491604, 0.21239125, 0.08804551, 0.08730757, 1.        ,\n",
              "        0.85723864, 0.20151171, 0.16200275, 0.14447728],\n",
              "       [0.29501242, 0.25583485, 0.09372089, 0.08893992, 0.85723864,\n",
              "        1.        , 0.22326634, 0.1806631 , 0.1558733 ],\n",
              "       [0.2530779 , 0.214717  , 0.08509508, 0.12527568, 0.20151171,\n",
              "        0.22326634, 1.        , 0.92754461, 0.45775827],\n",
              "       [0.2146434 , 0.17937458, 0.07946359, 0.1207279 , 0.16200275,\n",
              "        0.1806631 , 0.92754461, 1.        , 0.47179638],\n",
              "       [0.18585492, 0.16807197, 0.10627147, 0.12910021, 0.14447728,\n",
              "        0.1558733 , 0.45775827, 0.47179638, 1.        ]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarityAll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW3s0xqe7AEA",
        "outputId": "32c1d0c3-26e3-4374-a555-9653f196d1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize the true labels matrix\n",
        "real_plagiarism = np.zeros((9, 9))\n",
        "\n",
        "# Set the true labels for plagiarized pairs\n",
        "real_plagiarism[0:2, 0:2] = 1  # A0 and A1 are plagiarized\n",
        "real_plagiarism[2:4, 2:4] = 1  # B0 and B1 are plagiarized\n",
        "real_plagiarism[4:6, 4:6] = 1  # C0 and C1 are plagiarized\n",
        "real_plagiarism[6:9, 6:9] = 1  # D0, D1, and D2 are plagiarized\n",
        "\n",
        "# Print the true labels matrix\n",
        "print(real_plagiarism)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "uv7CvuQq7QKH",
        "outputId": "1cb4ae2b-8df8-41f6-9902-2805861351c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(real_plagiarism)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw38rgRJ8EeP",
        "outputId": "d8fdd241-2203-4408-fe37-b1ba84eda871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for All Documents: 0.9506172839506173\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert similarity matrix to binary predictions\n",
        "threshold = 0.5\n",
        "binary_predictions_All = (similarityAll > threshold).astype(int).flatten()\n",
        "\n",
        "# Convert true labels matrix to binary labels\n",
        "true_labels = real_plagiarism.flatten()\n",
        "\n",
        "# Compute accuracy score\n",
        "accuracy_All = accuracy_score(true_labels, binary_predictions_All)\n",
        "\n",
        "print(\"Accuracy for All Documents:\", accuracy_All)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZf4AaZ__Hfb"
      },
      "source": [
        "III. Text Classification "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8arZXD9n_H3q"
      },
      "outputs": [],
      "source": [
        "# Import NLTK and all the needed libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o22X-HVq_OSX",
        "outputId": "cba3382e-0552-4fb8-ef7b-359eb54ad44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Class                                            Message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab/spam.csv', encoding='latin-1')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZV9nWwbAHdh",
        "outputId": "0d419794-03fd-4835-8507-450bd3cbe4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Class    5572 non-null   object\n",
            " 1   Message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knYPudnoAfc1",
        "outputId": "c2acc6ab-a16c-448a-8bc5-25e7fe3d5ede"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define the preprocess_text function\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Lowercasing\n",
        "    tokens_lower = [token.lower() for token in tokens]\n",
        "    \n",
        "    # Stopword Removal\n",
        "    stop_words = set(stopwords.words('english'))  # Specify 'latin-1' stopwords\n",
        "    tokens_no_stopwords = [token for token in tokens_lower if token not in stop_words]\n",
        "    \n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens_stemmed = [stemmer.stem(token) for token in tokens_no_stopwords]\n",
        "    \n",
        "    # Return preprocessed tokens as a string\n",
        "    return ' '.join(tokens_stemmed)\n",
        "\n",
        "df['preprocessed_text'] = df['Message'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxHGRU4_FEYR",
        "outputId": "dfb70379-32d8-470c-86b1-5e48e93b9dfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       go jurong point , crazi .. avail bugi n great ...\n",
              "1                           ok lar ... joke wif u oni ...\n",
              "2       free entri 2 wkli comp win fa cup final tkt 21...\n",
              "3             u dun say earli hor ... u c alreadi say ...\n",
              "4              nah n't think goe usf , live around though\n",
              "                              ...                        \n",
              "5567    2nd time tri 2 contact u. u ï¿½750 pound prize...\n",
              "5568                         ï¿½_ b go esplanad fr home ?\n",
              "5569                        piti , * mood . ... suggest ?\n",
              "5570    guy bitch act like 'd interest buy someth els ...\n",
              "5571                                     rofl . true name\n",
              "Name: preprocessed_text, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['preprocessed_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WueI8km17vil",
        "outputId": "cb721a14-59ea-4f4c-e588-b6d61e5fae74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572, 7495)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "bow = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "print( bow.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dOPrNlzB8FCT",
        "outputId": "71036621-6c94-4cf9-c38f-b83b84ee4b75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ae4098e7-e001-442d-8f93-45a5f9882b8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000pe</th>\n",
              "      <th>008704050406</th>\n",
              "      <th>0089</th>\n",
              "      <th>0121</th>\n",
              "      <th>01223585236</th>\n",
              "      <th>01223585334</th>\n",
              "      <th>0125698789</th>\n",
              "      <th>02</th>\n",
              "      <th>...</th>\n",
              "      <th>½t</th>\n",
              "      <th>½te</th>\n",
              "      <th>½v</th>\n",
              "      <th>½wel</th>\n",
              "      <th>½ï</th>\n",
              "      <th>½û</th>\n",
              "      <th>½ûªm</th>\n",
              "      <th>½ûªt</th>\n",
              "      <th>½ûªv</th>\n",
              "      <th>ì¼1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 7495 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4098e7-e001-442d-8f93-45a5f9882b8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae4098e7-e001-442d-8f93-45a5f9882b8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae4098e7-e001-442d-8f93-45a5f9882b8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      00  000  000pe  008704050406  0089  0121  01223585236  01223585334  \\\n",
              "0      0    0      0             0     0     0            0            0   \n",
              "1      0    0      0             0     0     0            0            0   \n",
              "2      0    0      0             0     0     0            0            0   \n",
              "3      0    0      0             0     0     0            0            0   \n",
              "4      0    0      0             0     0     0            0            0   \n",
              "...   ..  ...    ...           ...   ...   ...          ...          ...   \n",
              "5567   0    0      0             0     0     0            0            0   \n",
              "5568   0    0      0             0     0     0            0            0   \n",
              "5569   0    0      0             0     0     0            0            0   \n",
              "5570   0    0      0             0     0     0            0            0   \n",
              "5571   0    0      0             0     0     0            0            0   \n",
              "\n",
              "      0125698789  02  ...  ½t  ½te  ½v  ½wel  ½ï  ½û  ½ûªm  ½ûªt  ½ûªv  ì¼1  \n",
              "0              0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "1              0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "2              0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "3              0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "4              0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "...          ...  ..  ...  ..  ...  ..   ...  ..  ..   ...   ...   ...  ...  \n",
              "5567           0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "5568           0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "5569           0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "5570           0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "5571           0   0  ...   0    0   0     0   0   0     0     0     0    0  \n",
              "\n",
              "[5572 rows x 7495 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dataframe from the BOW matrix and feature names\n",
        "bow_df = pd.DataFrame(bow.toarray(), columns=feature_names)\n",
        "\n",
        "bow_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}